% Copyright 2016 Bas van Meerten and Wouter Franssen
%
%This file is part of ssNake.
%
%ssNake is free software: you can redistribute it and/or modify
%it under the terms of the GNU General Public License as published by
%the Free Software Foundation, either version 3 of the License, or
%(at your option) any later version.
%
%ssNake is distributed in the hope that it will be useful,
%but WITHOUT ANY WARRANTY; without even the implied warranty of
%MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%GNU General Public License for more details.
%
%You should have received a copy of the GNU General Public License
%along with ssNake. If not, see <http://www.gnu.org/licenses/>.

\documentclass[11pt,a4paper]{article}
\include{DeStijl}

\usepackage[bitstream-charter]{mathdesign}
\usepackage[T1]{fontenc}
\usepackage[protrusion=true,expansion,tracking=true]{microtype}
\pgfplotsset{compat=1.7,/pgf/number format/1000 sep={}, axis lines*=left,axis line style={gray},every outer x axis line/.append style={-stealth'},every outer y axis line/.append style={-stealth'},tick label style={font=\small},label style={font=\small},legend style={font=\footnotesize}}
\usepackage{colortbl}


%Set section font
\usepackage{sectsty}
\allsectionsfont{\color{black!70}\fontfamily{SourceSansPro-LF}\selectfont}
%--------------------


%Set toc fonts
\usepackage{tocloft}
%\renewcommand\cftchapfont{\fontfamily{SourceSansPro-LF}\bfseries}
\renewcommand\cfttoctitlefont{\color{black!70}\Huge\fontfamily{SourceSansPro-LF}\bfseries}
\renewcommand\cftsecfont{\fontfamily{SourceSansPro-LF}\selectfont}
%\renewcommand\cftchappagefont{\fontfamily{SourceSansPro-LF}\bfseries}
\renewcommand\cftsecpagefont{\fontfamily{SourceSansPro-LF}\selectfont}
\renewcommand\cftsubsecfont{\fontfamily{SourceSansPro-LF}\selectfont}
\renewcommand\cftsubsecpagefont{\fontfamily{SourceSansPro-LF}\selectfont}
%--------------------

%Define header/foot
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LE,RO]{\fontfamily{SourceSansPro-LF}\selectfont \thepage}
\fancyhead[LO,RE]{\fontfamily{SourceSansPro-LF}\selectfont \leftmark}
\fancyfoot[C]{}
%--------------------

%remove page number from first chapter page
\makeatletter
\let\ps@plain\ps@empty
\makeatother
%----------------------
\usepackage{blindtext, color}
\definecolor{gray75}{gray}{0.75}
\newcommand{\hsp}{\hspace{20pt}}



\usepackage[hidelinks,colorlinks,allcolors=blue, pdftitle={The ssNake reference manual},pdfauthor={W.M.J.\ Franssen}]{hyperref}

\interfootnotelinepenalty=10000 %prevents splitting of footnote over multiple pages
\linespread{1.2}

%\usepgfplotslibrary{external}%creates all external tikz images that are included.
%\tikzexternalize[shell escape=-enable-write18]%activate externalization
%\tikzsetexternalprefix{GeneratedFigures/}
%\tikzset{external/force remake} %Enable forced remake



\begin{document}
%\newgeometry{left=72pt,right=72pt,top=95pt,bottom=95pt,footnotesep=0.5cm}
\input{Title.tex}

\thispagestyle{empty}
\newpage
\mbox{}

%\restoregeometry

\pagenumbering{roman}
%\pagestyle{empty}
\renewcommand\cfttoctitlefont{\color{black}\Huge\fontfamily{SourceSansPro-LF}\bfseries}
\microtypesetup{protrusion=false} % disables protrusion locally in the document
\setcounter{tocdepth}{2}
\tableofcontents % prints Table of Contents
\microtypesetup{protrusion=true} % enables protrusion
\addtocontents{toc}{\protect\thispagestyle{empty}}
%\pagestyle{plain}

\renewcommand\cfttoctitlefont{\color{black!70}\Huge\fontfamily{SourceSansPro-LF}\bfseries}


\pagenumbering{arabic}

\section{Running ssNake}
\subsection{Python versions}
ssNake had been programmed to run on both the python 2.x and 3.x branch. We developed ssNake using python 2.7.9 and 3.4.3, but somewhat older version might also be sufficient. 

\subsection{Numpy versions}
We have run into issue while using older versions of numpy. It seems that version 1.7.0 is the oldest that we support (some new commands have been introduced in this version, that ssNake makes use of). Development took place on version 1.8.2.



\section{File}
Using the ssNake load tools is quite easy. Go to File $\rightarrow$ Open. Navigating and double clicking on the desired file then loads the data. Many formats supported by ssNake (like Bruker and Varian) have their data in a folder, in which several files with a fixed name are present. For these formats, loading any of the files in this directory is accepted (ssNake searches for the expected files in the selected directory). Loading large data files might take some time, depending on your computer hardware.

When loading the data, the user is prompted to give in a name for the data by which it is identified in the workspace selector (see the Worspaces section for more on this). The default name is the name of the file (or folder for data in which the file name is fixed). If the name already exists as a workspace, the name spectrum\textit{n} is used (with \textit{n} the lowest integer that is not in use).


\subsection{Formats}
ssNake is able to extract NMR data from a number of formats from several vendors. The following table summarizes the support.

\begin{center}
\begin{tabular}{lc}
\toprule
Name & Specification \\
\midrule
\rowcolor{gray!30!white}
Varian/Agilent & VnmrJ 2 and newer. fid and data (spectrum)\\
Bruker & Topspin and XWinNMR (fid \& ser,1r/i \& 2rr/ii) \\
\rowcolor{gray!30!white}
Chemagnetics & ??? \\
Magritek & Both 1D and 2D data \\
\rowcolor{gray!30!white}
Simpson & 1D and 2D, -ascii and -binary \\
JSON & ssNake JSON file (ascii)\\
\rowcolor{gray!30!white}
Matlab & ssNake .mat file (binary)\\
\bottomrule
\end{tabular}
\end{center}

Generally, ssNake loads the data raw data and searches for some variables (e.g. spectral width and spectrometer frequency). The above data formats do not support data with more then two dimensions in a nice way. Getting the higher dimensions is therefore not straightforward. ssNake treats this data as 2D, after which you can split the data yourselves using Matrix $\rightarrow$ Split.

\subsubsection*{Varian/Agilent}
Loading a Varian/Agilent fid file requires a \textit{procpar} file and a \textit{fid} file. From the \textit{procpar}, the spectral frequency and the spectral width in one or two dimensions is extracted. The \textit{fid} file is then checked for the version (VnmrJ 2 or 3) and the data is extracted from this file.

For processed data (\textit{data}, in the datdir folder for example) it searches for a \textit{procpar} file in that directory or in the parent folder, from which additional parameters are extracted.

\subsubsection*{Bruker}
The Bruker load first checks for the \textit{acqus} and \textit{acqu2s} files and extracts the number of points in both dimensions, the spectral widths and the spectral frequency. Also, the bitorder is checked, which describes the way the data is saved in the \textit{fid} or \textit{ser} file. Using this, the data is extracted.

Bruker processed spectra can be loaded from \textit{1r} and \textit{1i} files for 1D data, \textit{2rr} and \textit{2ii} for 2D data, and \textit{2rr} and \textit{2ir} for hypercomplex data. It additionally takes parameters from \textit{procs} or \textit{proc2s} files in that directory. Moreover, the spectral frequency is extracted from the \textit{acqus} and/or \textit{acqu2s} files located \textit{two directories up}.

 
\subsubsection*{Chemagnetics}
Loading Chemagnetics data requires a \textit{acq} (and \textit{acq\_2} for 2D) and \textit{data} file. From the former, the number of points in both dimensions is extracted, the spectral widths and the spectral frequency. All the data points are then extracted form the \textit{data} file, and reshaped to a 2D array when necessary.

\subsubsection*{Magritek}
Magritek requires two or three files: \textit{acqu.par} for the spactral variables, and a file that ends with \textit{.1d}. For 2D data, a file that ends with \textit{.2d} is also needed. As with the other formats, the number of data points in the two dimensions is extracted from the parameter file (along with the spectral data) and the binary data in the \textit{.1d} or \textit{.2d} is unpacked.

\subsubsection*{Simpson}
Simpson data files are plain text files, \textit{.fid} or \textit{.spe} as file extension. From the file, the number of points in both dimensions is extracted, and the spectral widths. The spectral frequency is \textit{not} included in the Simpson format, and is put at 0. Simpson files cannot contain a mixture of time and frequency data (both dimensions must be the same type). Simpson binary data is also supported, but not raw binary.

\subsubsection*{JSON}
Loads a JSON file that is saved with ssNake. File must have the \textit{.json} or \textit{.JSON} extension.

\subsubsection*{Matlab}
Loads a Matlab file that is saved with ssNake. File must have the \textit{.mat} or \textit{.MAT} extension. Also supports .mat files that have been resaved to matlab v7.3 format.


\subsubsection*{Unsupported file formats}
Currently, we support all the data formats that we have access to. While we have some code lying around for loading JEOL data, for example, we cannot include this if we cannot test it. If you want your favourite data format to be support by ssNake, please send us a request along with some sample data (1D and 2D).

\subsection{Open}
When using ssNake's load function, ssNake analyses the selected file name and the names of other files in the directory to figure out the format you want to load. ssNake only needs to check for files that are actually needed for loading the data, so removing useless files from the format does not pose a problem. Below, the checks used by ssNake in this function can be found for each format.

\begin{center}
\begin{tabular}{lll}
\toprule
Name & Folder contains files & File extension\\
\midrule
\rowcolor{gray!30!white}
Varian/Agilent fid &  procpar and fid & \\
Varian/Agilent spectrum&  data and procpar or ../procpar & \\
\rowcolor{gray!30!white}
Bruker fid &  acqus (and acqu2s for 2D)  &\\
\rowcolor{gray!30!white}
&and fid or ser&\\
Bruker spectrum & (1r/1i) or (2rr and 2ii/2ir) &\\
  & with procs/proc2s  &\\
 &and ../../acqus and ../../acqu2s & \\
\rowcolor{gray!30!white}
Chemagnetics &  acq (and acq\_2 for 2D) and data &\\
Magritek &  acqu.par and *.1d or *.2d&\\
\rowcolor{gray!30!white}
Simpson &  & .fid or .spe \\
JSON & & .json or .JSON\\
\rowcolor{gray!30!white}
Matlab & & .mat or .MAT\\
\bottomrule
\end{tabular}
\end{center}





\subsection{Save data}
Naturally, ssNake can also be used to save data. When saving data, the current ND data is saved, along with the spectral widths, frequencies and if the axis is in time or frequency units. Also, ppm references are saved, along with the processing history. Undo information is \textit{not} saved.

\subsubsection*{JSON}
JSON (JavaScript Object Notation) is a ascii format (i.e. regular text) used to save data structures. Within ssNake this can be used to save the current data in a clear, human readable format. As JSON data is in ascii, it is not efficient in file size and in speed. If these are necessary then consider saving the data as a matlab binary.

\subsubsection*{MATLAB}
The MATLAB binary format is a open source format in which many different types of data can be saved. Also, it is the native format of MATLAB, which can be used for more special data manipulation, if necessary. As the format is binary, it is efficient in both speed and file size. The content of the file is the same as the JSON file.


\subsection{Export data}
Using ssNAke you can also export your data. Exporting never saves all the info our own formats do, so there will be loss of information. It is suggested you only use these formats for exchanging data to another program, but not for archiving.


\subsubsection*{Simpson}
Simpson is a general NMR simulation program with its own data format. The format only supports 1D and 2D data, and only if the data in both dimensions is of the same type (i.e. both spectrum, or both time). Apart from that, Simpson is a ascii format, and therefore has the same speed restrictions as the JSON format. The parameters that are saved within the Simpson data are restricted (no offset frequency), so when loading it back into ssNake some information is lost. We therefore advise to use the Simpson format only for transferring data to another program.

\subsubsection*{ASCII (1D/2D)}
This option saves the current data to a bare ascii format (text file). The first column is the axis in units of Hz or seconds. The next columns are alternating real and imaginary for all traces in the 2D data. For 1D data, only a single set of real and imaginary data is printed. The axis of dimension 1 of the 2D data is not saved.

\subsubsection*{Figure}
The Figure option can be used to export any Figure plot within ssNake. The title, axis labels and size of the Figure can be changed. Be aware that choosing a to small height can cause the x-axis label to disappear. After all the titles have been set, pushing `Save' will save the Figure to a directory of your choice. The Figure can be saved in vector format (.eps, .pdf, .svg), in lossless pixel format (.png), and in lossy pixel format (.jpg). We advice to use vector formats to make high quality pictures.

\subsection{Quit}
Closes the ssNake application.

\section{Workspaces}
Within ssNake you can have multiple data files opened. Each loaded file gets its own environment in which you can process the data. These are called workspaces. All ssNake workspaces are independent, meaning that the data from workspace 1 cannot be changed while viewing any other workspace. Going back to a workspace from another goes back to the same view as before:  nothing is discarded when switching between workspaces. Also: every workspace has its own undo/redo information. Some tools can transfer data from other workspaces to the current workspace. You can find more about these tools later on, in their respective sections.

When loading data, ssNake prompts for a name. This will become the name of the workspace in which the data is loaded. The title of the graph will be set to this name, and the name will be set in the list of opened workspaces in Workspaces $\rightarrow$ Active. You can also switch workspace using the tabs that are created for every workspace. Note that you cannot have multiple workspaces with the same name.

\subsection{Duplicate}
Makes a copy of the current workspace to another workspace, of which the name is asked. All the data and the current view is copied to this new workspace. No undo and redo data is transferred. Also, the current workspace is now the new, duplicated one.

\subsection{Delete}
Deletes the current workspace and all references to it. The view is changed to the next workspace in the list. Be aware that there is no way to undo this!

\subsection{Rename}
Renames the current workspace. Note that two workspaces cannot have the same name.

\subsection{Active}
Shows a list of all workspaces. The current workspaces can be changed by clicking on another workspace name.

\subsection{Keyboard shortcuts}
ssNake features several keyboard shortcuts to work with the workspaces. Below is a list of all the combinations.
\begin{center}
\begin{tabular}{ll}
\toprule
Combination & Effect \\
\midrule
\rowcolor{gray!30!white}
Ctrl + w & Close current workspace\\
Ctrl + d & Duplicate workspace\\
\rowcolor{gray!30!white}
Ctrl + Page Up & Change current workspace to the one above in the list\\
Ctrl + Page Down & Change current workspace to the one below in the list\\
\bottomrule
\end{tabular}
\end{center}
When the current workspace is the last in the list, and Ctrl + Page Down is pressed, the current workspace is set to the first in the list.

\section{Macros}
Macros can be used to save a particular series of action performed on the data, for later fast reuse. Say that you want to load several data files, and want to set the size of them to 4096 points and perform a Fourier transform. Doing this many times can be annoying. When you create a macro to do this, you only need to execute the macro for every data file. Thus saving time and making sure all are processed in an identical way. Also, macros are shared between workspaces: there is only one pool of macros. How to use macros is explained below. 

\subsection{Start recording}
To create a macros, you must tell ssNake that you want to record a series of action, to be saved in the macro. Executing Macros $\rightarrow$ Start Recording prompts for a name of the future macro, and enables the recording. From now on, all the actions you perform on the data are recorded and saved in this macro.

\subsection{Stop recording}
After some actions have been performed (Fourier, zero fill, phasing\ldots   ) the recording of the macro can be stopped using Macros $\rightarrow$ Stop Recording. 

\subsection{Run}
Can be used to run the selected macro on the current data.

\subsection{Delete}
Delete a macro.

\subsection{Save}
Can be used to save a macro to the disk as a .json file. This is a plain text file, in which you can see all the steps that are executed when running this macro.

\subsection{Load}
Loads a saved macro in ssNake. Execution of the macro can then be performed using Macros $\rightarrow$ Run.

\subsection{Notes on usage of macros}
Note that ssNake only records the actions that are not undone. If you perform an action when recording is on, and you undo it while recording, the macro has no entries. However, performing two actions that cancel each other \textit{are} recorded. For example, issuing Fourier twice has no net effect, but a macro of this includes both commands.

SOME PART ABOUT RUNNING MACROS ON MORE OR LESS DIMENSIONS THEN THEY WERE CREATED FOR.




\section{Edit}
\subsection{Undo}
In ssNake, every action that causes a change in the data can be undone. When such an action is performed, the undo list is increased with one entry, in which the information is stored as how to undo the performed action. Sometimes this involves the inverse operation (e.g. for fft/inverse fft), but for some actions the old data must be preserved and put back when an undo is requested. Duplicating data to another workspace does not copy the undo list.

Undo cannot be used the undo the current view to the previous view as this is not an operation that changes the data.

\subsection{Redo}
When Undo is used, the action that is undone is put in the redo list. Using Undo and then Redo therefore performs no net action. Every time a new action (i.e. something other then redo) is performed the redo list is cleared.

\subsection{Reload}
This action reloads the data from the original source. All undo and redo information is retained., so you can undo back to before you reloaded the data. Note that the undo information can take quite some memory on your computer, especially for bigger data sets.

\section{Tools}
This section explains all the options included in the Tools menu. 

\subsection{Real}
Real puts the imaginary values of all data points at zero.

\subsubsection*{Background}
In some NMR experiments, only the real value of the magnetization during a specific period is measured. In this case it is convenient to zero the imaginary part to force further processing to ignore this data.


\subsection{Imag}
Imag puts the real values of all data points at zero.

\subsection{Abs}
Abs replaces all complex datapoints by the length of the vector they span in the 2D complex plane. That is:
\begin{equation*}
F_\text{new} = \sqrt{\text{real}(F_\text{old})^2 + \text{imag}(F_\text{old})^2}
\end{equation*}
for all points in the complex data. These values are put as the real part. The imaginary part is zeroed.

\subsection{Phasing}
Opens a tool that can be use to change the phasing in the current spectrum or fid. Supports zero order, first order and autophasing.

\subsubsection*{Background}
NMR data is usually recorded as complex data. Here the real part can be said to be the x-magnetization, and the imaginary part the y-magnetization. This gives the NMR signal as a complex vector, that is rotating in the complex plane during the signal acquisition. An ideal NMR signal consists of a cosine in the real part, and a sine in the imaginary part. This gives, after Fourier transform, a spectrum were a pure absorption lineshape (i.e. a peak) is seen. Depending on the way the time signal is recorded, there can be a distortion to this line, as a constant phase is added to both the sinusoids. With zero order phase correction, an additional phase is added to both the complex and the real part, to adjust for this effect. When expressed in complex exponentials, the following holds:
\begin{equation}
f_\text{new} = f_\text{old}\cdot\text{e}^{i\pi\cdot\theta/180} 
\end{equation}
were $f$ is a complex value in the time or frequency domain and $\theta$ the desired phase correction in degrees. When using this zero order phase correction, all points in the time or frequency domain get the same phase correction.

In the spectral domain, a \textit{first} order phase correction is also defined. This leads to a phase correction that linearly depends on the frequency offset with respect to a set central frequency. 


\subsubsection*{ssNake implementation}
Selecting phasing in the tools menu opens the phasing window. In this windows, the zero and first order phasing can be set, as well as the reference frequency (centre point) for the first order phasing. The values can be either filled in the boxes,  changed by pushing the left and right buttons, or set by dragging the slider to the left or the right. For zero order phase correction, the limits are -180 and 180 degrees. For first order correction, these are -540 and 540 degrees. Higher values for the first order correction sometimes make sense, and can be filled in the box directly. Note that the values for the zero order correction are circular, so that -180 and 180 degrees lead to the same effect.

While in this menu, the effect of a certain phasing can be immediately viewed in the ssNake window. When a good setting is reach, `Ok' can be pushed to apply the phasing. Note that for multidimensional data, the preview only shows the current trace. Pushing `Ok' the applies the same phasing correction on all the traces (might take some time for large data). If the phasing should only be applied on the current spectrum or fid, the box `Single slice' can be ticked. Note that you still have to push `Ok' to apply the phasing.

Apart from manual phasing, ssNake also supports two types of autophasing: zero order only, and zero and first order. When pushing these buttons, ssNake will search for the best phasing in the \textit{current} trace, with only first order phasing correction, or with both zero and first order. Do note that the setting that ssNake finds might not be the best: phasing an NMR spectrum is tricky and has no unique mathematical solution. However, for a fast analysis it can be useful.

Also, note that first order phase correction has no meaning in NMR when applied to the time domain. ssNake therefore always applies first order phasing in the \textit{frequency} domain. When first order phasing is applied when viewing the time domain signal, ssNake transforms to the spectral domain, does the phase correction, and transforms back. As Fourier transforms are quite fast, this provides no issues when viewing the effect of the phase correction.



\subsection{Swap echo}
A tool to swap the time domain data symmetrically around a selected point.

\subsubsection*{Background}
In some NMR experiments, the rise and fall of a spin echo is recorded. One way of processing this data is to remove all the data points before the echo maximum, and subsequently treat the data as a regular FID. In some cases it is more useful to use the full data, rise and fall, of the echo signal. Directly Fourier transforming such data leads to massive first order phase distortion. This can be circumvented by swapping the echo around the centre. In this case, the data is split in two parts: the data from the start of the measurement until the top of the echo, and the data from the top of the echo until the last point. The latter data is put leftmost, the former right. The new signal then starts with a decay and rises again at the end. Due to the symmetry of the echo, the Fourier transform of this signal will have zero imaginary signal, while the real signal is still the same as if a regular FID is transformed. This means that phasing such a line can be easily done.

\subsubsection*{ssNake implementation}
Echo swapping is done by left clicking on the echo maximum of the time signal. By default, the swapping is set at the centre of the time signal. After left clicking, a preview is shown. Pushing `Apply' applies the transformation to all traces of this dimension. Also, the tag `Whole echo' is set in the footer. When this is on, Fourier transforming does not multiply the first point by 0.5 (as is needed for data that decays to zero), and line broadening is applied symmetrically around zero.


\subsection{Offset correction}
Subtracts the average value of the selected data points from all data points.

\subsubsection*{Background}
It can sometimes happen that NMR data does not decay to zero, but to another value. In this case, a time signal with zero frequency and no decay can be thought to have been added to the NMR signal. Usually, this is due to issues with the electronics, and does not imply a NMR signal with these properties. For proper analysis of the signal, this offset should be removed, as it leads to a signal at 0 Hz, which can interfere with the spectrum. This can be solved by subtracting the average value of the last points of the time domain data from all the data points.

\subsubsection*{ssNake implementation}
Using the Offset correction tool opens a new window. By default, the last 20\% of the time data is selected as containing only noise (of which the average is the offset which should be subtracted). Left clicking two times in the graph sets the limits between which the average value is calculated. Pushing apply subtracts this value from all time data points. If the data has more dimensions then 1, the average value is subtracted from all data points. Take note that the average is only calculated for the current graph. If you want to correct the offset for each graph you can select the `Single slice' option, and do the correction separately in each desired trace.

\subsection{Baseline correction}
Fits a polynomial line of a given order through the current spectrum while ignoring the selected parts. This line is then subtracted from the spectrum.

\subsubsection*{Background}
In some NMR spectra, experimental conditions were such that a non-informative baseline is present in the spectrum. This can be due to electronic reasons (e.g. pulse ringing) or due to background signals. This usually means that the first points in the time signal are corrupted. In some cases, removing the first data points is the best option, but this leads to signal loss and a large first order phasing error. In these cases, it can be more convenient to try to subtract the errors in the frequency domain. This is done by fitting a $n$th degree polynomial through  the spectrum, and subtract this line from the spectrum. For this, it is essential that the regions of spectral information (i.e. the NMR peaks) are not included in the fit. Failing to do this will cause the baseline correction to attempt to remove the peaks. 

Baseline correction is mostly a visual thing. In the case of ssNake, the degree of the polynomial to be subtracted has to be put in. Usually, putting a very high value leads to strange results. This, however, depends on the spectrum to be corrected.

\subsubsection*{ssNake implementation}
In ssNake, baseline correction is performed by fitting a $n$th degree polynomial through the spectrum, i.e.:
\begin{equation*}
S_\text{corr} = \sum_{i=0}^n a_i x^i ,
\end{equation*}
with $a_i$ the amplitude of the $i$th degree polynomial. Fitting this to the spectrum is a mathematical operation with a single unique solution. Prior to doing this, specific parts of the spectrum can be selectively ignored in the fitting procedure. This can be done by left clicking in the spectrum at the two limits of the area that is to be ignored. The area is then marked with a red background. This way, multiple areas can be selected. Pressing  `Fit' then performs and shows the fit. Apply subtracts the line from the spectrum. Note that by default this single fit is subtracted from \textit{all} the traces. This is useful if the background is identical in all of them. Alternatively, the box `Single slice' can be ticked to only apply the correction on the current spectrum.

\subsection{Subtract averages}
Subtracts the average of a region from the respective data. The analysis is performed independently for every slices in the $n$D data. This effectively does the same as Offset Correction, but then for each trace independently.

\subsubsection*{ssNake implementation}
Opening this tool gives a window were the left and right limit of the selected data can be set. Alternatively, left clicking on the plot sets the start limit on the first click, and the end limit on the second click. Pushing apply performs the subtraction.

\subsection{Reference deconvolution}
Uses the FIDDLE algorithm to deconvolute a peak shape in the spectrum.

\subsubsection*{Background}
Due to issues with magnetic field inhomogeneity (i.e. shimming), peaks in an NMR spectrum can have a weird shape with extra ridges and small peaks on the side. In some cases it is known from prior knowledge that the visible peak should be a single Lorentzian line. If so, the line can be deconvoluted to give this Lorentzian line. Naturally, all other lines in the spectrum should have the same distortions. Using the known shape of the easy Lorentzian reference, all other lines can also have their shape corrected.

\subsubsection*{ssNake implementation}
Using the `Reference deconvolution' opens a window, in which the region of the reference signal has to be set (by left clicking, or by filling in the values). Additionally, the new linewidth of the peak has to be specified. Note that the algorithm cannot increase resolution, only make better lineshapes. Filling in a too small linewidth will result in a heavily distorted spectrum. Pushing apply performs the analysis for all traces.

\subsection{Correct Bruker digital filter}
Corrects a Bruker fid to start at $t=0$.

\subsubsection*{Background}
In theory, the recording of an NMR signal starts directly after the excitation point. The signal can then be easily described by a decaying exponential (or another function) and the Fourier transform does not show surprises. NMR data measured on a Bruker device, however, has the peculiar attribute that it starts \textit{before} the physical start of the signal. The origin of this lies in the way Bruker spectrometers use their digital filter, of which the details will not be described here. Direct Fourier transformation of this signal will lead to massive oscillations in the baseline of the resulting spectrum.

To be able to handle Bruker NMR data, this detection error has to be corrected. The preferred way for this seems to apply a strong first order phase correction in the spectrum that (due to Fourier principles) rolls the time domain data in such a way that the first point is now the start of the real signal. Due to this procedure, the points that were at the front of the time signal are now at the end. Apparently this leads to better results than just removing this data.

\subsubsection*{ssNake implementation}
To automate this process, ssNake uses information from a handy text by W.\ M.\ Westler and F.\ Abildgaard. Every Bruker NMR spectrometer has its own characteristics, and therefore needs a different amount of first order phase correction. For older Bruker hardware, the amount of correction is found by extracting two parameters from the Bruker acqus file, and to use a lookup table supplied by Westler \& Abildgaard. For newer hardware, this value can be read directly from the acqus file.

Using this tool opens a windows, in which you have to open (again) the current Bruker file. ssNake then finds the desired phase correction and applies it to all traces. 


\section{Matrix}
This section describes the ssNake matrix manipulation tools. NMR data is nothing more then a data matrix of a specific dimension. Using the matrix tools, you can change the size of a dimension, split the data into more dimension, integrate, multiply, mirror etc. In the following, the different supported matrix manipulations will be introduced.


\subsection{Sizing}
The sizing tool can be used to edit the number of points in the current dimension. 

\subsubsection*{Background}
The number of point taken in an NMR time signal is usually restricted, as increasing the acquisition time leads to more noise (if the signal has decayed) or adds too much strain on the device (if decoupling is used). As the number of points in the spectrum is equal to the number of points in the time signal, this limits the \textit{digital} resolution of the spectrum, making it less easy to extract the desired data. However, if the signal has decayed at the end, the digital resolution in the spectrum can be enhanced by adding zeroes at the end, without effecting the spectrum in terms of signal-to-noise and appearance. This is termed `zero filling' and is often used in NMR.

If the time signal has not fully decayed, the signal abruptly changes to zero when zero-filling is applied. This leads to distortions in the spectrum (i.e. sinc wiggles) as the time signal is effectively multiplied with a block function. General Fourier theory then states that the spectrum must then be convoluted with the Fourier transform of the block function, which is $\sin(x)/x$, i.e. sinc.

\subsubsection*{ssNake implementation}
Selecting `Matrix $\rightarrow$ Sizing' creates a sizing window. In here a single number has to be filled in the box titled `Size'. Decimal values will be rounded to the nearest integer. Apart from numbers, the command `k' (or `K') is also supported, which stands for `1024'. When using this definition there has to be a number before the `k'. A valid input would therefore be: `2k'. Which sets the number of points to $2 \cdot 1024=2048$. Pressing `Apply' executes the sizing command on all traces in all dimensions.

If the supplied number is larger than the current size, zeroes are added at the right-hand side of the time signal. If the value is lower, points are removed from the right-hand side of the time signal. If the whole echo type is on, the zeroes are added in the centre of the time signal, or points are taken symmetrically from the centre, if the size is reduced. Alternatively, the position of the zero filling can be specified by left-clicking in the spectrum, or by manually filling in the desired offset value in the box `Offset'.

When applied to the frequency domain, zero filling makes no real sense. Therefore, ssNake always applies it in the time domain. So when the size is chaed within a spectrum, it is transformed back to the time domain, the size is changed, and a forward Fourier transform gets the data back to the frequency domain.

\subsection{Shift data}
Shifts the data to the left or to the right, by removing data points on the left or on the right, and filling with zeroes on the other side. Negative shifts are left shifts, positive right shifts.

\subsubsection*{Background}
Data shifting can be used if some data points on the left or right of the time signal are unnecessary or unwanted. When measuring a spin echo, for example, it is not uncommon to start recording the signal some microseconds before the expected echo top, to make sure the full signal is measured. The data can then be left shifted to remove the data points before the echo maximum, and yield a regular spectrum.

\subsubsection*{ssNake implementation}
Starting the shift data tool creates an input window. Within this window, a integer number must be filled in that equals the number of data points of the  desired \textit{right} shift. Left shifts can be made by using negative values. Alternatively, the arrows on the right and left side of the input box can be used to shift the data in the direction of the arrow. The effect of the operation on the current 1D can be seen in the main window. When pushing `Apply' the shift is performed on all traces of the nD data.

ssNake can also perform the time domain shift from within the frequency domain. When in a spectrum, an inverse Fourier transform is used to go back to the time domain. The data is then shifted with the desired measure, and a forward Fourier transform gives the spectrum of the shifted time signal. The effect of the sift on the current 1D can be seen in the main window. As this calculation is a bit more involved, it can take some time if the data set is large.


\subsection{Integrate}
Integrates a specific part of the current dimension on all traces.

\subsubsection*{Background}
As NMR is a quantitative technique (when applied correctly), the area under the different peaks in a spectrum is a representative for the relative number of nuclei that resonant at this frequency. Calculating the integral of these peaks can therefore supply the user with an indication on the composition of the material that is analysed. Integration in ssNake using the matrix tool integrates across (specific parts) of the current dimension. Therfore, the resulting data will have one dimension fewer than before. Say, for example, you have a set of 2D data, of which every trace has the same signal, but a different intensity of this signal. When in the second dimension (in which the peak is shown) the peak can be integrated by supplying the left and right limit of the peak. This will result in 1D data, of which every point represents the integral of the selected area of one of the spectra.

\subsubsection*{ssNake implementation}
When using the integration matrix tool, a window pops up, were you have to select the limits of the area you want to integrate in the current dimension. This can be done by typing in the numbers of the data points, or more conveniently by left clicking in the spectrum. The first click sets the first limit, the second click the second limit. Pushing apply then performs the integration. Be aware that integration values can depend on, amongst others, the amount of zerofilling that is used.

\subsection{Sum}
Sums a specific part of the current dimension on all traces. Is implemented in the same way as integrating, only no scaling with the step sizes is performed.

\subsection{Max}
Takes the maximum value of the selected part in the current dimension on all traces. Implementation is the same as with integration.

\subsection{Min}
Takes the minimum value of the selected part in the current dimension on all traces. Implementation is the same as with integration.

\subsection{Max position}
Returns the x value of the maximum position (i.e. top of a peak) within the selected area for all traces.

\subsubsection*{Background}
When analysing some experiments, it is useful to make a plot of the position of a peak versus some changing variable (e.g. time, temperature). This features allows the user to extract such data. It finds the maximum value within the selected region, and extracts the corresponding x-value. It does this for all traces, and therefore reduces the number of dimensions by 1. For example, if one has 2D data, of which the most intense peak in D2 shifts linearly in D1, this tool tool can be used to generate 1D data that shows this linear relation.

\subsection{Min position}
Returns the x value of the minimum position within the selected area for all traces. Works the same as Max position.

\subsection{Average}
Returns the average of the selected region. Implementation is the same as with integration.

\subsection{Diff}
Differentiates the data in the current dimension (i.e. returns the difference between each data point and the next data point). This is equal to the slope between the points. Remember that NMR data is the frequency domain is always depicted from right to left, so the direction of differentiating is different in the time domain than in the frequency domain (or, in fact, it is the same but $looks$ different).

\subsection{Cumsum}
Performs a cumulative sum on the data in the current dimension. This means that each point is now equal to its old value, and those of all the previous points added. Remember (as with Diff) that the frequency domain is mirrored, and the direction of Cumsum is also different.


\subsection{Extract part}
Deletes all parts of the current dimension that are outside the selected region.


\subsubsection*{ssNake implementation}
This function can be used to delete parts from the current spectrum or fid. Left clicking on a prt sets the first limit on the first click, and the second limit on the second click. Apply deletes all parts outside this region on all traces. When doing this in the spectrum, the spectral width and zero point (reference frequency) are also changed to keep all peaks at the same frequency.

\subsection{Flip L/R}
Flips (i.e. mirrors) the left and right side of the current dimension. The axis is not flipped.

\subsection{Delete}
Deletes specific data points from the current dimension. Should be entered in array from. For example: [1,2,40] deletes data points 1, 2 and 40. Remember that ssNake uses the python way of array indexing: 0 is the first point. The above code therefore deletes the second, third and forty--first data point. Do remember that the indexing goes from right to left in the case the current dimension is a spectrum (the frequency axis is flipped).

\subsection{Split}
Splits the current dimension in $n$ parts with an equal number of data points. The newly created dimension is named D1, and all the other dimension numbers are increased by one (shifted one lower). This tool can only spilt the data in parts of equal size. It is therefore necessary to make sure that the size of the data in the current dimension is divisible by $n$, or in math.

\subsection{Multiply}
Multiplies the y-values of the data in the current dimension by a given number. If a single number is supplied, all the points are multiplied by this number. Alternatively, an array with the same length as the data can be given to specify a position dependent multiplication. For example, for a dimension with 3 data points: [1,3.34,2]. This multiplies the first data point by 1, second by 3.34, etc. Do not forget the about the mirroring in the spectral domain (see Diff)!

\subsection{Reorder}
Reorders the data in the current dimension. Input is an array with the new, desired positions. For example, [0,2,1] keeps the position of the first element (`0'), but interchanges the second and the third. It is also possible to supply the input array by loading a filer (as is used in Non-Uniform Sampling). If the new data length is longer than the old, the missing points are filled with zeros. Also, the length of the desired new dimension can be given. If the length of the final data is shorter than this value, some zeros are appended.

\subsection{Concatenate}
Concatenates (i.e. sticks) that data of dimension $n$ after dimension $n+1$. So if the original data is 10x5x3, and dimension 2 is selected, it becomes 10x15. This can be seen as the opasite of the `Split' function. Note that after applying this function the numbers of the dimensions in the ssNake window changes accordingly.



\section{Fitting}
In NMR spectroscopy, the shape of the resonance lines can provide information on the strength of interactions that the nucleus experiences. ssNake can, as many other programs, fit some idealized lineshapes with are often encountered in real life spectra. Fitting in ssNake ranges from trivial `full width at half maximum' (FWHM) fitting, to the complex quadrupolar Czjzek distribution. The following section will explain the way ssNake handles the different types of spectra it can fit, and which equations are used to simulate the different spectra.

\subsection{Fitting basics}
Roughly speaking, ssNake uses two types of fitting procedures: those with a mathematical solution, and those who have to be approximated iteratively. An example of the former type is the fitting of the width of a peak at halve height (FWHM). This involves nothing more than finding the left and right side of the peak (at halve height) and to calculate the width of this interval. This can be done in one easy mathematical procedure, and involves no iterative loop. The second type of fitting procedure is used for the powder lineshapes (e.g. quadrupolar and chemical shift lineshapes). With these problems, there is no direct mathematical solution. We are searching a parameter space for the solution that best fits the experimental spectrum. This is done by trying different settings, and qualifying how well these fit. Based on these attempts, a new setting is tested. This is continued until an optimum has been found. There are several ways to do such an iterative fitting: ssNake uses the Nelder-Mead algorithm \cite{nelder1965simplex} (also known as ``Simplex'').

\subsubsection*{Powder distributions and line shape fitting}
ssNake supports fitting procedures for several idealized lineshapes commonly encountered in solid state NMR. In the following sections, the equations for these shapes fill be given. In all cases, the fitted shape represents an ideal version assuming perfect excitation, and no mixed lineshape effects (e.g. quadrupolar and CSA at the same time). Note that the quality of the fit is determined by the digital resolution, which is the same as in the spectrum that is fitted. In many cases, convergence towards to optimum solution is difficult, as our fitting procedure is sensitive for local optima. It is therefore good practice to have a good initial guess. Use the `Sim' button to show the current guess, and put all variables to reasonable values.

Simulation of powder spectra is done by getting intensities and frequencies of all the crystallite angles contained in a crystal file. These crystal files (which are not files in our case, but merely matrices) are made on the fly by ssNake depending on the `Cheng' number supplied by the user from the fitting window. Higher values of this number lead to more powder orientations and more accurate results. Note that the number of angles increases exponentially with the Cheng number, which can lead to very slow fits. The resulting frequency/intensity pairs will be add to a vector of the current intensities. Nearly always, the found frequency is not a value of the x-axis, in which case it is shifted to the nearest point that is. This introduces a small error in the simulation, but if the digital resolution is good enough to show the pattern nicely, this error will be very small. Also note that values that are not within the limits of the x-axis are discarded, no aliasing is performed.

\subsection*{ZCW crystal files}
As explained in the previous section, simulation of powder patterns requires averaging over a sphere. In practice, only a finite amount of angles (the polar angles $\theta$ and $\phi$) is selected and saved in the crystal file. There is no perfect way to do this, and therefore there exist multiple methods to do this. We use the ZCW method (named after Zaremba, Conroy, and Wolfsberg \cite{zaremba1966good,conroy1967molecular,cheng1973investigations}), being both fast and accurate. The required input is a single number: the `Cheng' number. This number specifies the amount of crystal orientations via the Fibonacci series, with Cheng(0) being `1', Cheng(1) `2' and subsequent values the sum of the two previous:
\begin{equation}
F_M = F_{M-1} + F_{M-2}	\quad .
\end{equation} 
From this, a list $js$ is made, going from 0 to 1 (not including) with the number of steps equal to the Fibonacci number. Phi is equal to:
\begin{equation}
\phi = \dfrac{2  \piup}{c_2} \cdot \text{mod}(F_{M-1} \cdot js, 1)
\end{equation} 
with $c_2$ a scaling factor (see below) and $F_{M-1}$ the value of the Fibonacci series for $\text{Cheng} - 1$. In practice this means that (due to the `mod'), the list makes $F_{M-1}$ passes through the region 0:$2  \piup/c_2$, with slightly different values for every pass. Theta is equal to:
\begin{equation}
\theta = \text{acos}(c_0 (c_1 \cdot js - 1)) \quad .
\end{equation}
In the above, the $c$ parameters define the limits over which the angles are calculated. ssNake provides three options for this: a full sphere, a hemisphere (the upper half) and an octant (a quarter of the upper half). In the simulations that ssNake performs, the symmetry of the NMR interactions is high, and only the octant needs to be sampled. The $c$ values are:
\begin{equation}
\mathbf{c} = \left\{
  \begin{array}{ll}
    (1, 2, 1) & \text{full sphere}\\
    (-1, 1, 1) &\text{hemisphere}\\
    (-1, 1, 4) &\text{octant}\\
  \end{array}
\right. \quad .
\end{equation}
The source code of this can be found in \texttt{zcw.py}. For more information on powder averaging see the paper by Mattias Ed\'{e}n \cite{eden2003computer}.



\subsection{S/N}
S/N (or SNR) calculates the signal-to-noise ratio between a defined section of noise, and a peak. SNR is a useful way to describe the quality of a spectrum, with too low values being a sign for inaccurate data. In ssNake, opening the S/N tool creates a window, in which the limits of the section of noise has to be set, as well as the region with the peak of interest. Left clicking in the plot can set these values (noise limits first, then signal limits). Note that it is essential that the region that is specified as `noise' really is noise. Any remaining signal will disrupt the SNR calculation. When the limits are set, ssNake directly calculates the SNR, using:
\begin{equation}
\text{SNR} = a_\text{max} / \text{std(NoiseRange)}
\end{equation}
with $a_\text{max}$ the maximum value within the range with the signal, and $\text{std(NoiseRange)}$ the standard deviation of the noise.

\subsection{FWHM}
FWHM, or Full Width at Half Maximum, is a tool to calculated the width of a peak. Selecting the tool in the menu creates a window, in which the boundaries of the peak of interest have to be set, for ssNake to search for the width of the peak. Make sure that there is only one peak in the selected window, otherwise the result might be inaccurate. The easiest way to select the regions is by left clicking in the spectrum. After valid input is given, ssNake directly calculates the FWHM in the units of the current axis. The order of input of the two limits is not important for the eventual calculation.

\subsection{Centre of Mass}
Calculates the centre of mass of a selected part of a spectrum or FID. For a symmetric peak, this is equal to the centre of the peak. However, for an asymmetric peak, identifying the centre is not possible via visual methods and a centre of mass calculation is required. Opening the tool creates an input window, in which the limits have to be set (as with the FWHM tool). After these are set, the centre of mass is calculated in units of the current axis, using:
\begin{equation}
R = \frac{1}{M} \sum_i y_i \cdot x_i  \quad,
\end{equation}
with $M = \sum y_i$ and $y_i$ the y-value corresponding to x-value $x_i$.

\subsection{Second order quadrupole static}
This fitting routine can be used to fit a static powder lineshape that is caused by the second order quadrupolar effect. A simplex method is used to find the (local) optimal solution. It is therefore necessary to make sure the initial parameters are somewhat close to the final fit, especially for fits with multiple sites.

\subsubsection*{Formulae}
The second order quadrupole static relies on some relatively standard formulae: those of the second order quadrupolar coupling. This equation can be split up in two parts: an angle independent factor, and the angular factors. This latter part is then split in three parts depending on the influence of the asymmetry parameter $\eta$. In short:

\begin{equation}
\nu = -\dfrac{3{C_\text{Q}}^2}{6\nu_0(2I(2I-1))^2}(I(I+1)-3/4)(A+B\cdot\eta+C\cdot\eta^2)
\end{equation}
With:
\begin{align}
A &= -\dfrac{27}{8}\cos(\theta)^4+\dfrac{15}{4}\cos(\theta)^2-\dfrac{3}{8} \\
B &= \left(-\dfrac{9}{4}\cos(\theta)^4+2\cos(\theta)^2+\dfrac{1}{4}\right)\cos(2\phi) \\
C &=-\dfrac{1}{2}\cos(\theta)^2+\dfrac{1}{3}+\left(-\dfrac{3}{8}\cos(\theta)^4+\dfrac{3}{4}\cos(\theta)^2-\dfrac{3}{8}\right)\cos(2\phi)^2
\end{align}
For a given cheng number (i.e. number of powder orientations), the $A$, $B$ and $C$ parameters are contant, and only have to be calculated once for the fitting procedure.


%A = -27/8.0*np.cos(theta)**4+15/4.0*np.cos(theta)**2-3/8.0
%B = (-9/4.0*np.cos(theta)**4+2*np.cos(theta)**2+1/4.0)*np.cos(2*phi)
%C = -1/2.0*np.cos(theta)**2+1/3.0+(-3/8.0*np.cos(theta)**4+3/4.0*np.cos(theta)**2-3/8.0)*np.cos(2*phi)**2



\section{Help}
\subsection{Chemical shift conversion tool}
In NMR literature there are several definitions in use for describing the chemical shift tensor. This tool provides an easy way to inter convert them. The definitions are based on the very useful website of Klaus Eichele (\url{http://anorganik.uni-tuebingen.de/klaus/nmr/index.php?p=conventions/csa/csa}). In the most useful conventions, the three tensor values $\delta_\text{xx}$, $\delta_\text{yy}$ and $\delta_\text{zz}$ are rewritten to an average value, a width and an asymmetry. Below follow the definitions of the different conventions.

The primary convention is called the `Standard Convention'. This convention just gives the three principal components of the tensor, without any restructuring, called $\delta_\text{11}$, $\delta_\text{22}$ and $\delta_\text{33}$. They are ordered in such a way that: $\delta_\text{11} \geq \delta_\text{22} \geq \delta_\text{33}$.

The second convention we call the `xyz Convention'. This is essentially the same as the Standard Convention, only the ordering is different. We now have $\delta_\text{xx}$, $\delta_\text{yy}$ and $\delta_\text{zz}$. With $|\delta_\text{zz}-\delta_\text{iso}| \geq |\delta_\text{xx}-\delta_\text{iso}| \geq |\delta_\text{yy}-\delta_\text{iso}|$. With $\delta_\text{iso}$ the isotropic value, defined as the average of the three principal components. In this definition, $\delta_\text{zz}$ is the value furthest away from the isotropic value, $\delta_\text{yy}$ the closest, and $\delta_\text{xx}$ the remaining value.

The third definition is the Haeberlen definition (or Haeberlen-Mehring-Spiess). Here, the principal components are ordered as in the xyz convention, only now they are redefined into a width, asymmetry and isotropic value. With $\delta_\text{iso} = (\delta_\text{xx} +\delta_\text{yy} +\delta_\text{zz})/3$, $\delta_\text{aniso} = \delta_\text{zz} -\delta_\text{iso}$ and $\eta = (\delta_\text{yy}-\delta_\text{xx})/\delta_\text{aniso}$. This way, the asymmetry parameter $\eta$ always lies between 0 and 1. Not that due to the ordering of the principal components, the sign of the anisotropy (i.e. the width) is ill defined for $\eta=1$.

The final definition is the Herzfeld-Berger definition. This convention uses the Standard Convention as a basis, and then defines the isotropic value as $\delta_\text{iso} = (\delta_\text{11} + \delta_\text{22} + \delta_\text{33})/3$, the span as $\Omega = \delta_\text{11} - \delta_\text{33}$ and the skew as $\kappa = 3(\delta_\text{22}-\delta_\text{iso})/\Omega$. This way, the span is always positive, while the skew lies between -1 and 1.



\subsubsection*{Use of the tool}
Using the chemical shift conversion tool is quite easy. You can fill in all the necessary values for one convention, and push the `Go' button next to it to convert it to all the other definitions. Note that ssNake also checks the definitions. So if you mess up the order of the Standard Convention, for example, it will be put in the correct order. The same is done for values that are outside the defined limits (e.g. $\eta$ and $\kappa$). Pushing `Reset' will reset all the values to 0.

\subsection{Quadrupole coupling conversion tool}
Nuclei with a spin quantum number greater than 1/2 have an asymmetric charge distribution. This leads to a quadrupolar moment, and thus to a coupling between the nucleus and the electronic field gradient at the nuclear site. Just as for chemical shift, there are multiple convention in use to describe the resulting quadrupolar tensor. Apart from being a symmetric tensor, Laplace relation states that the sum of the field gradients in all direction should be zero (otherwise the nuclei would experience a net force). Due to this, there is no isotropic term, and the quadrupolar coupling can be described by two numbers: the strength and the asymmetry. Of these there are two conventions in use: C$_\text{Q}$ and $\omegaup_\text{Q}$. When the field gradients in the three independent directions are $V_\text{xx}$, $V_\text{yy}$ and $V_\text{xx}$ (with $|V_\text{zz}| \geq |V_\text{yy}| \geq |V_\text{xx}|$), C$_\text{Q}$ is defined as:
\begin{equation}
C_\text{Q} = \dfrac{eV_\text{zz}Q}{\hbar} = \dfrac{e^2qQ}{\hbar}
\end{equation}
or the more commonly used C$_\text{Q}/2\piup$ (which has Hz as unit):
\begin{equation}
C_\text{Q}/2\piup = \dfrac{eV_\text{zz}Q}{h} = \dfrac{e^2qQ}{h} \quad .
\end{equation}
With $e$ the elementary charge, $Q$ the quadrupole moment (in m$^2$), $h$ the Planck constant (and $\hbar$ the reduced Planck constant). Alternatively, a value that is scaled with the spin quantum number $I$ is used:
\begin{equation}
\omegaup_\text{Q}/2\piup = \dfrac{3e^2qQ}{2I(2I+1)h} = \dfrac{3}{2I(2I+1)} C_\text{Q}/2\piup	\quad .
\end{equation}
For both definitions, the asymmetry is defined as:
\begin{equation}
\eta = \dfrac{V_\text{xx} -V_\text{yy}}{V_\text{zz}}
\end{equation}
which, due to the ordering of the fields gradient components, is always between 1 and 0.

Generally, only the $C_\text{Q}$ and $\omegaup_\text{Q}$ definitions are used, and the field gradients themselves are not shown. However, if the quadrupolar coupling for a nucleus in a material is known, the field gradients can be calculated by using the known quadrupolar moment of the nucleus. This way, the quadrupole coupling for another isotope at the same site in the material can be calculated by reversing the equation with a new moment and spin quantum number.

\subsubsection*{Use of the tool}
Using the quadrupole conversion tool is quite easy. You can fill in all the necessary values for one convention, and push the `Go' button next to it to convert it to all the other definitions. Note that ssNake also checks the definitions. So if you have an asymmetry below 0, it will reorder the field gradients in such a way it lies between 1 and 0 again. To calculate the field gradients from the quadrupole coupling constant (or the other way around), the quadrupolar moment should be given (which starts at `ND", being `not defined'). When starting from the field gradients, ssNake checks if they sum to 0 (which they should). If not, the difference is subtracted from the three values, to make sure it is. Note that only the absolute quadrupolar coupling is found in NMR, so pay no heed to the absolute sign of the field gradients.



\bibliographystyle{BibStyle}
\bibliography{ReferenceManual}

\end{document}
